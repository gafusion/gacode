#! /usr/bin/env bash
#
# SCRIPT:
#  gyro.XT5
#
# FUNCTION:
#  Parallel execution script
#
# JAGUAR SYSTEM INFO:
# - Cray XT5
# - 224,256 processor cores
# - 18,688 compute nodes
# - (2x) AMD Opteron 2435 (Istanbul) 6-core CPUs per compute node running at 2.6GHz
# - (2x) ccNUMA nodes per compute node (each CPU referred to as NUMA node)
# - each compute node has 16GiB RAM (1.3GiB per core)
# - (1x) SeaStar2+ ASIC per compute node arranged in 3D torus network topology
#
#  FIXED Hardware parameters
CORES_PER_NODE=12
NUMAS_PER_NODE=2
#---------------------------------------------------

simdir=${1}
nmpi=${2}
exec=${3}
nomp=${4}
numa=${5}
mpinuma=${6}

# Default to densely-packed pure-MPI.
if [ $numa -eq 0 ]
then
   numa=$NUMAS_PER_NODE
fi
if [ $mpinuma -eq 0 ]
then
   mpinuma=$(($CORES_PER_NODE/$NUMAS_PER_NODE))
fi

# nmpi = MPI tasks
# nomp = OpenMP threads per MPI task
# numa = NUMAs active per node
# mpinuma = MPI tasks per active NUMA 

cd $simdir

#=========================================================================
# Calculator for parallel layout (identical code in queue_go.*)

# See if we are asking for too many NUMAs
if [ $numa -gt $NUMAS_PER_NODE ] 
then
  echo 'Too many NUMAs per node requested'
  exit 1
fi

# See if we are asking for too many OpenMP tasks
i1=$(($nomp*$mpinuma))
i2=$(($CORES_PER_NODE/$NUMAS_PER_NODE)) 
if [ $i1 -gt $i2 ] 
then
   echo 'Too many OpenMP tasks per MPI process'
   exit 1
fi

# MPI tasks per node
mpinode=$(($mpinuma*$NUMAS_PER_NODE))
# Nodes requested 
nodes=$(($nmpi/$mpinode))

# If we need part of a node, then add a node
if [ $nmpi -gt $(($nodes*$mpinode)) ] 
then
   nodes=$(($nodes+1))
   echo "WARNING: Using partial node"
fi

# Final core counts
cores_requested=$(($nodes*$CORES_PER_NODE))
cores_used=$(($nomp*$nmpi))
#=========================================================================

export MPICH_MAX_THREAD_SAFETY=funneled
export OMP_NUM_THREADS=$nomp
aprun -n $nmpi -N $mpinode -d $nomp -S $mpinuma -ss $exec

